{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train BERT for the Preselection of Reports\t \n",
    "\n",
    "For fine-tuning, the 'simpletransformers' library is used, as it only requires a few lines of code for the training. The library can be downloaded from Github via:  (https://github.com/ThilinaRajapakse/simpletransformers). \n",
    "\n",
    "## Creating the enviroment\n",
    "\n",
    "\n",
    "```bash\n",
    "conda create --name=finetuning \n",
    "conda install tensorflow-gpu pytorch scikit-learn\n",
    "\n",
    "cd transformers \n",
    "pip install .\n",
    "\n",
    "git clone https://github.com/ThilinaRajapakse/simpletransformers\n",
    "cd simpletransformers\n",
    "pip install .\n",
    "\n",
    "git clone https://github.com/NVIDIA/apex\n",
    "cd apex\n",
    "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n",
    "\n",
    "conda install ipykernel pandas\n",
    "ipython kernel install --user --name=finetuning\n",
    "\n",
    "pip install python-box ipywidgets\n",
    "jupyter nbextension enable --py widgetsnbextension\n",
    "```\n",
    "'nvidia-apex' raises an error about incompatible CUDA versions. The function to check for errors is commented out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from simpletransformers.classification import ClassificationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path to folder containing data file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $DATADIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATADIR + 'train-evaluable.csv', header=0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MultiLabelClassificationModel\n",
    "args={'output_dir': 'outputs/',\n",
    "      'cache_dir': 'cache_dir/',\n",
    "      'fp16': False,\n",
    "      'fp16_opt_level': 'O1',\n",
    "      'max_seq_length': 512,           \n",
    "      'train_batch_size': 8,\n",
    "      'gradient_accumulation_steps': 10,\n",
    "      'eval_batch_size': 12,\n",
    "      'num_train_epochs': 10,          \n",
    "      'weight_decay': 0,\n",
    "      'learning_rate': 4e-5,\n",
    "      'adam_epsilon': 1e-8,\n",
    "      'warmup_ratio': 0.06,\n",
    "      'warmup_steps': 0,\n",
    "      'max_grad_norm': 1.0,\n",
    "      'logging_steps': 50,\n",
    "      'save_steps': 2000,  \n",
    "      'evaluate_during_training': True,\n",
    "      'overwrite_output_dir': True,\n",
    "      'reprocess_input_data': True,\n",
    "      'n_gpu': 2,\n",
    "      'use_multiprocessing': True,\n",
    "      'silent': False,\n",
    "      'threshold': 0.5,\n",
    "      'wandb_project': 'bert-for-radiology',\n",
    "      \n",
    "      # for long texts     \n",
    "      'sliding_window': True,\n",
    "      'tie_value': 1}\n",
    "\n",
    "model_names= ['../models/pt-radiobert-base-german-cased/', 'bert-base-german-cased', '../models/pt-radiobert-from-scratch/', 'bert-base-multilingual-cased']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(DATADIR + 'test-evaluable.csv', header=0)\n",
    "args[\"output_dir\"] = 'outputs/final/radbert-binary/'\n",
    "model = ClassificationModel('bert', '../models/pt-radiobert-base-german-cased/', args=args)\n",
    "model.train_model(data, eval_df = test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"output_dir\"] = 'outputs/final/radbert-binary/'\n",
    "model = ClassificationModel('bert', '../models/pt-radiobert-base-german-cased/', args=args)\n",
    "model.train_model(data)\n",
    "\n",
    "args[\"output_dir\"] = 'outputs/final/fsbert-binary/'\n",
    "model = ClassificationModel('bert', '../models/pt-radiobert-from-scratch/', args=args)\n",
    "model.train_model(data)\n",
    "\n",
    "args[\"output_dir\"] = 'outputs/final/gerbert-binary/'\n",
    "model = ClassificationModel('bert', 'bert-base-german-cased', args=args)\n",
    "model.train_model(data)\n",
    "\n",
    "args[\"output_dir\"] = 'outputs/final/multibert-binary/'\n",
    "model = ClassificationModel('bert', 'bert-base-multilingual-cased', args=args)\n",
    "model.train_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(DATADIR + 'test-evaluable.csv', header=0)\n",
    "\n",
    "with open('results-binary.csv', 'w+') as f:\n",
    "    f.write('model,' + ','.join(map(str, range(1,501))) + ',\\n')\n",
    "\n",
    "model_dirs = ['outputs/final/radbert-binary/', 'outputs/final/fsbert-binary/', 'outputs/final/gerbert-binary/', 'outputs/final/multibert-binary/']\n",
    "\n",
    "for model_dir in model_dirs:\n",
    "    model = ClassificationModel('bert', model_dir, args=args)\n",
    "    pred, raw =  model.predict(test.text)   \n",
    "        \n",
    "    for rep in ['outputs', 'final', '/']:\n",
    "        model_dir=model_dir.replace(rep, '')\n",
    "              \n",
    "    with open('results-binary.csv', 'a') as f:\n",
    "        f.write(model_dir +  ',' + ','.join(map(str, raw)).replace('\\n', '') +'\\n')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast-bert",
   "language": "python",
   "name": "fast-bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
